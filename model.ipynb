{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "# Import the numpy library, which is fundamental for scientific computing in Python\n",
    "import numpy as np\n",
    "# Import the SimpleImputer class from sklearn, which provides basic strategies for imputing missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Import SGDClassifier from sklearn, which is a linear classifier \n",
    "# (SVM or logistic regression) optimized using Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# Import the cross_val_score function for cross-validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Read the preprocessed training data from a CSV file into a DataFrame\n",
    "train_processed = pd.read_csv(\"dataset/train_processed.csv\")\n",
    "\n",
    "# Read the preprocessed test data from a CSV file into a DataFrame\n",
    "test_processed = pd.read_csv(\"dataset/test_processed.csv\")\n",
    "\n",
    "# Separate the features (X) and the target variable (y) for the training data\n",
    "# Drop the 'Transported' column from the training data to form the feature set\n",
    "X_train = train_processed.drop(\"Transported\", axis=1)\n",
    "\n",
    "# Extract the 'Transported' column as the target variable for the training data\n",
    "y_train = train_processed[\"Transported\"]\n",
    "\n",
    "# Copy the test dataset into a new variable (this will be used for making predictions)\n",
    "X_test = test_processed.copy()\n",
    "\n",
    "# Create an instance of SimpleImputer with the strategy to replace missing values using the mean of each column\n",
    "# The missing_values parameter specifies what value will be considered as missing, in this case 'np.nan' which represents NaN values in numpy\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# Apply the imputer to the training data\n",
    "# This involves calculating the mean of each column in X_train (fit) and then replacing missing values in X_train with these means (transform)\n",
    "# The result is stored in X_train_tr, which now contains the training data with missing values imputed\n",
    "X_train_tr = imp_mean.fit_transform(X_train)\n",
    "\n",
    "# Convert the transformed training data (after imputation) back into a DataFrame.\n",
    "# This step is necessary because the imputer returns a numpy array. \n",
    "# We preserve the original column names and indices from X_train.\n",
    "X_train = pd.DataFrame(X_train_tr, columns = X_train.columns, index = X_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an instance of MinMaxScaler.\n",
    "# MinMaxScaler is a method to scale the features to a specific range, typically [0, 1].\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the training data (X_train).\n",
    "# This step calculates the minimum and maximum values of each feature in X_train, \n",
    "# which will be used to scale the data.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the training data using the fitted scaler.\n",
    "# This scales each feature in X_train to the range [0, 1] using the min and max values computed earlier.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Convert the scaled data (which is in the form of a numpy array) back to a pandas DataFrame.\n",
    "# This step is necessary because scaling operations often return numpy arrays rather than DataFrames.\n",
    "# The original column names and indices from X_train are used to ensure that the structure of the data remains consistent.\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "36 fits failed out of a total of 72.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/root/anaconda3/envs/learn/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.79708009 0.79236328\n",
      " 0.79374442 0.79558429 0.79454889 0.79420403        nan        nan\n",
      " 0.78580556 0.78339054 0.7866104  0.78569066 0.78661127 0.7828152 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier': RandomForestClassifier(), 'classifier__max_depth': 10, 'classifier__n_estimators': 50, 'scaler': StandardScaler()}\n",
      "Best score: 0.7970800886410738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define a Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Placeholder for the scaler\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = [\n",
    "    # {\n",
    "    #     'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "    #     'classifier': [SGDClassifier()],\n",
    "    #     'classifier__max_iter': [900, 1000, 2000],\n",
    "    #     'classifier__tol': [1e-3, 1e-4, 1e-5]\n",
    "    # },\n",
    "    {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': list(range(0, 200, 50)),  # Example parameters for RandomForestClassifier\n",
    "        'classifier__max_depth': list(range(0, 30, 10))\n",
    "    }\n",
    "]\n",
    "# Set up Grid Search\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Fit on your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best combination of preprocessing steps and classifier parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7615597 , 0.76121463, 0.77528478])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming X_train and y_train are previously defined and properly formatted\n",
    "# Initialize the SGDClassifier with specified parameters.\n",
    "# max_iter is the maximum number of passes over the training data,\n",
    "# tol is the stopping criterion, and random_state ensures reproducibility.\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "# Fit the model to the training data (both features and target variable)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Perform 3-fold cross-validation to evaluate the accuracy of the classifier.\n",
    "# This process divides the dataset into 3 parts, trains the model on 2 parts and \n",
    "# tests on the 3rd part, this is repeated 3 times each with a different part as the test set.\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measuring Accuracy Using Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766735679779158\n",
      "0.7712215320910973\n",
      "0.7770107007248878\n"
     ]
    }
   ],
   "source": [
    "# Import StratifiedKFold for stratified sampling to ensure representative ratio of each class.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Import clone to make deep copies of the SGD classifier without copying attached data.\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Create a StratifiedKFold object for cross-validation, with 3 splits.\n",
    "# The data is shuffled for each fold, and a random state is set for reproducibility.\n",
    "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over each fold created by the StratifiedKFold object.\n",
    "# `train_index` and `test_index` are arrays of indices for the training and test set respectively.\n",
    "for train_index, test_index in skfolds.split(X_train, y_train):\n",
    "    # Clone the original SGDClassifier. This ensures the classifier is fresh for each fold.\n",
    "    clone_clf = clone(sgd_clf)\n",
    "\n",
    "    # Create training and test sets for this fold using the provided indices.\n",
    "    X_train_folds = X_train.iloc[train_index]\n",
    "    y_train_folds = y_train.iloc[train_index]\n",
    "    X_test_fold = X_train.iloc[test_index]\n",
    "    y_test_fold = y_train.iloc[test_index]\n",
    "\n",
    "    # Fit the cloned classifier on the training part of the fold.\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "\n",
    "    # Predict on the test part of the fold.\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "\n",
    "    # Count the number of correct predictions.\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "\n",
    "    # Calculate and print the accuracy for this fold.\n",
    "    print(n_correct / len(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cross_val_predict function from sklearn.model_selection.\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Generate cross-validated estimates for each input data point.\n",
    "# The function is similar to cross_val_score, but instead of returning the evaluation scores,\n",
    "# it returns the predictions made on each test fold.\n",
    "# This means that for each element in the input, a prediction is made by a model trained on the\n",
    "# rest of the data. Here, it uses the SGD classifier, 3-fold cross-validation (cv=3),\n",
    "# and the training data (X_train, y_train).\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix function from sklearn.metrics.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a confusion matrix, which is a summary of prediction results on a classification problem.\n",
    "# The number of correct and incorrect predictions are summarized with count values and broken down by each class.\n",
    "# This is comparing the true target values (y_train) against the predictions made by the model (y_train_pred).\n",
    "# The matrix gives insights into the types of errors being made by the classifier.\n",
    "cm = confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8191721132897604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import precision_score and recall_score from sklearn.metrics.\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Calculate the precision of the model.\n",
    "# Precision is the ratio of true positives (correct positive predictions) to the total number of positive predictions made.\n",
    "# In other words, it answers the question: \"Out of all the instances the classifier predicted as positive,\n",
    "# how many were actually positive?\".\n",
    "# This is computed by comparing the true labels (y_train) with the predicted labels (y_train_pred).\n",
    "precision_score(y_train, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6870717222476016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the recall score of the model.\n",
    "# Recall, also known as sensitivity or true positive rate, is the ratio of true positives \n",
    "# to the sum of true positives and false negatives.\n",
    "# In other words, it answers the question: \"Out of all the actual positive instances, \n",
    "# how many did the classifier correctly identify as positive?\".\n",
    "# This is computed by comparing the true labels (y_train) with the predicted labels (y_train_pred).\n",
    "recall_score(y_train, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7473291925465838"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the f1_score function from sklearn.metrics.\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate the F1 score for the model.\n",
    "# The F1 score is the harmonic mean of precision and recall. \n",
    "# It provides a single score that balances both the concerns of precision and recall in one number.\n",
    "# An F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "# It is particularly useful when you need to balance precision and recall, \n",
    "# and is especially useful in uneven class distribution scenarios where one class is rare.\n",
    "# This is computed by comparing the true labels (y_train) with the predicted labels (y_train_pred).\n",
    "f1_score(y_train, y_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7660186356838836"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
